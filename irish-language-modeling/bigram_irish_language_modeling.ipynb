{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    original_text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(filename, content):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(str(content))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    # remove punctuations !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    punctuation_list = [\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\"–\",\"€\",\"•\",\"«\",\"»\",\"’\",\"“\",\"”\",\"£\"]\n",
    "    for punctuation in punctuation_list:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "\n",
    "    # remove emojis\n",
    "    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    text = RE_EMOJI.sub(r'', text)\n",
    "\n",
    "    # substitute multiple spaces with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    # normalize text to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = readfile('train.txt')\n",
    "\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "text = preprocess_data(text)\n",
    "\n",
    "writefile(\"cleaned_train.txt\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_pair_dict = {\n",
    "    \"a|á\": { \"keywords\": [\"a\",\"á\"], \"probability\": 0 },\n",
    "    \"ais|áis\": { \"keywords\": [\"ais\",\"áis\"], \"probability\": 0 },\n",
    "    \"aisti|aistí\": { \"keywords\": [\"aisti\",\"aistí\"], \"probability\": 0 },\n",
    "    \"ait|áit\": { \"keywords\": [\"ait\",\"áit\"], \"probability\": 0 },\n",
    "    \"ar|ár\": { \"keywords\": [\"ar\",\"ár\"], \"probability\": 0 },\n",
    "    \"arsa|ársa\": { \"keywords\": [\"arsa\",\"ársa\"], \"probability\": 0 },\n",
    "    \"ban|bán\": { \"keywords\": [\"ban\",\"bán\"], \"probability\": 0 },\n",
    "    \"cead|céad\": { \"keywords\": [\"cead\",\"céad\"], \"probability\": 0 },\n",
    "    \"chas|chás\": { \"keywords\": [\"chas\",\"chás\"], \"probability\": 0 },\n",
    "    \"chuig|chúig\": { \"keywords\": [\"chuig\",\"chúig\"], \"probability\": 0 },\n",
    "    \"dar|dár\": { \"keywords\": [\"dar\",\"dár\"], \"probability\": 0 },\n",
    "    \"do|dó\": { \"keywords\": [\"do\",\"dó\"], \"probability\": 0 },\n",
    "    \"gaire|gáire\": { \"keywords\": [\"gaire\",\"gáire\"], \"probability\": 0 },\n",
    "    \"i|í\": { \"keywords\": [\"i\",\"í\"], \"probability\": 0 },\n",
    "    \"inar|inár\": { \"keywords\": [\"inar\",\"inár\"], \"probability\": 0 },\n",
    "    \"leacht|léacht\": { \"keywords\": [\"leacht\",\"léacht\"], \"probability\": 0 },\n",
    "    \"leas|léas\": { \"keywords\": [\"leas\",\"léas\"], \"probability\": 0 },\n",
    "    \"mo|mó\": { \"keywords\": [\"mo\",\"mó\"], \"probability\": 0 },\n",
    "    \"na|ná\": { \"keywords\": [\"na\",\"ná\"], \"probability\": 0 },\n",
    "    \"os|ós\": { \"keywords\": [\"os\",\"ós\"], \"probability\": 0 },\n",
    "    \"re|ré\": { \"keywords\": [\"re\",\"ré\"], \"probability\": 0 },\n",
    "    \"scor|scór\": { \"keywords\": [\"scor\",\"scór\"], \"probability\": 0 },\n",
    "    \"te|té\": { \"keywords\": [\"te\",\"té\"], \"probability\": 0 },\n",
    "    \"teann|téann\": { \"keywords\": [\"teann\",\"téann\"], \"probability\": 0 },\n",
    "    \"thoir|thóir\": { \"keywords\": [\"thoir\",\"thóir\"], \"probability\": 0 },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict = {}\n",
    "# word_count_dict_builtin = {}\n",
    "words = text.split()\n",
    "\n",
    "num_all_words = len(words)\n",
    "\n",
    "for word in words:\n",
    "    if word in word_count_dict:\n",
    "        word_count_dict[word] += 1\n",
    "    else:\n",
    "        word_count_dict[word] = 1\n",
    "        \n",
    "for key in keyword_pair_dict:\n",
    "    keyword1 = keyword_pair_dict[key][\"keywords\"][0]\n",
    "    keyword2 = keyword_pair_dict[key][\"keywords\"][1]\n",
    "    \n",
    "#     word_count_dict_builtin[keyword1] = text.count(keyword1)\n",
    "#     word_count_dict_builtin[keyword2] = text.count(keyword2)\n",
    "\n",
    "# print(word_count_dict_builtin[\"thoir\"])\n",
    "# print(word_count_dict[\"thoir\"])\n",
    "\n",
    "#  P(thoir) = C(thoir) / [C(thoir) + C(thòir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = ['I','love','you']\n",
    "\n",
    "# count bigram\n",
    "for i in range(len(words)):\n",
    "    \n",
    "    if i == 0:\n",
    "        # a word with nothing preceding\n",
    "        preceding_word = \"^\";\n",
    "    else:\n",
    "         # normal pairs of words   \n",
    "        preceding_word = words[i-1];\n",
    "    \n",
    "    bigram = preceding_word + \" \" + words[i]\n",
    "    if bigram in word_count_dict:\n",
    "        word_count_dict[bigram] += 1\n",
    "    else:\n",
    "        word_count_dict[bigram] = 1\n",
    "\n",
    "# count when the word is the last word of the sentence\n",
    "bigram = words[-1] + \"$\"\n",
    "if bigram in word_count_dict:\n",
    "    word_count_dict[bigram] += 1\n",
    "else:\n",
    "    word_count_dict[bigram] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5086159985488845\n"
     ]
    }
   ],
   "source": [
    "print(word_count_dict[\"thóir\"] / (word_count_dict[\"thóir\"] + word_count_dict[\"thoir\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_1 = keyword_pair_map[0][0];\n",
    "# word_2 = keyword_pair_map[0][1];\n",
    "# prob_word_1 = word_count_dict[word_1]\n",
    "# prob_word_2 = word_count_dict[word_2]\n",
    "\n",
    "# normalized_prob = prob_word_1 / (prob_word_1 + prob_word_2)\n",
    "# print(normalized_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keyword_pair_dict:\n",
    "    word_1 = keyword_pair_dict[key][\"keywords\"][0]\n",
    "    word_2 = keyword_pair_dict[key][\"keywords\"][1]\n",
    "    prob_word_1 = word_count_dict[word_1]\n",
    "    prob_word_2 = word_count_dict[word_2]\n",
    "    \n",
    "    normalized_prob_word_1 = prob_word_1 / (prob_word_1 + prob_word_2)\n",
    "    \n",
    "    keyword_pair_dict[key][\"probability\"] = normalized_prob_word_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_unigram():\n",
    "    test_text = readfile('test.txt')\n",
    "\n",
    "    test_sentences = test_text.split(\"\\n\");\n",
    "    test_word_choices = []\n",
    "    answer_list = [\"Id,Expected\"]\n",
    "    running_number = 1\n",
    "    for sentence in test_sentences:\n",
    "        start_index = sentence.find(\"{\")\n",
    "        end_index = sentence.find(\"}\")\n",
    "\n",
    "        word_choice = sentence[start_index+1:end_index]\n",
    "        if(word_choice):\n",
    "            prob = keyword_pair_dict[word_choice][\"probability\"]\n",
    "            answer_list.append(\"{},{}\".format(running_number, prob))\n",
    "        running_number += 1\n",
    "    answer = \"\\n\".join(answer_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = generate_submission_unigram()\n",
    "# writefile('submission7.csv', submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_prob(sentence):\n",
    "    prob_word_choice_1 = 0\n",
    "    \n",
    "    start_index = sentence.find(\"{\")\n",
    "    end_index = sentence.find(\"}\")\n",
    "    \n",
    "    word_choice = sentence[(start_index+1):end_index] # \"thoir|thóir\"\n",
    "\n",
    "    if word_choice:\n",
    "        [word_choice_1, word_choice_2] = word_choice.split('|'); # word_choice_1 = \"thoir\" and word_choice_2 = \"thóir\"\n",
    "    #     print(word_choice_1)\n",
    "    #     print(word_choice_2)\n",
    "\n",
    "        words = sentence.split();\n",
    "        index = words.index(\"{\" + word_choice + \"}\")\n",
    "        if index == 0:\n",
    "            prev_word = \"^\"\n",
    "            next_word = words[1]\n",
    "\n",
    "        elif index == len(words)-1:\n",
    "            prev_word = words[index - 1]\n",
    "            next_word = \"$\"\n",
    "\n",
    "        else:\n",
    "            prev_word = words[index - 1]\n",
    "            next_word = words[index + 1]\n",
    "\n",
    "        # E.g. Tá Dora agus Bróigín ar {thoir|thóir} réalt-ainmhithe in éineacht le Pegaso.\n",
    "        # p1 = P(thoir|ar) * P(réaltainmhithe|thoir) \n",
    "        # c1 = count(\"ar thoir\") * counbt(\"thoir réaltainmhithe\")\n",
    "\n",
    "        # p2 = P(thòir|ar) * P(réaltainmhithe|thòir)\n",
    "        # c2 = count(\"ar thòir\") * count(\"thòir réaltainmhithe\")\n",
    "        # P(thoir) = p1/(p1+p2)\n",
    "        # P(thoir) = c1/(c1+c2)\n",
    "\n",
    "        word_1_bigram_1 = prev_word + \" \" + word_choice_1\n",
    "        word_1_bigram_2 = word_choice_1 + \" \" + next_word\n",
    "\n",
    "        word_2_bigram_1 = prev_word + \" \" + word_choice_2\n",
    "        word_2_bigram_2 = word_choice_2 + \" \" + next_word\n",
    "\n",
    "        count_word_1_bigram_1 = word_count_dict[word_1_bigram_1] if word_1_bigram_1 in word_count_dict else 1\n",
    "        count_word_1_bigram_2 = word_count_dict[word_1_bigram_2] if word_1_bigram_2 in word_count_dict else 1\n",
    "\n",
    "        count_word_2_bigram_1 = word_count_dict[word_2_bigram_1] if word_2_bigram_1 in word_count_dict else 1\n",
    "        count_word_2_bigram_2 = word_count_dict[word_2_bigram_2] if word_2_bigram_2 in word_count_dict else 1\n",
    "\n",
    "        c_1 = count_word_1_bigram_1 * count_word_1_bigram_2 \n",
    "        c_2 = count_word_2_bigram_1 * count_word_2_bigram_2\n",
    "        prob_word_choice_1 = c_1 / (c_1 + c_2) if c_1 + c_2 > 0 else keyword_pair_dict[word_choice][\"probability\"]\n",
    "\n",
    "    return prob_word_choice_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_bigram():\n",
    "    test_text = readfile('test.txt')\n",
    "\n",
    "    test_sentences = test_text.split(\"\\n\");\n",
    "    test_word_choices = []\n",
    "    answer_list = [\"Id,Expected\"]\n",
    "    running_number = 1\n",
    "    for test_sentence in test_sentences:\n",
    "        if test_sentence:\n",
    "            prob = calculate_bigram_prob(test_sentence)\n",
    "\n",
    "            answer_list.append(\"{},{}\".format(running_number, prob))\n",
    "            running_number += 1\n",
    "    answer = \"\\n\".join(answer_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_submission_bigram())\n",
    "\n",
    "writefile('submission_bigram_1.csv', generate_submission_bigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
