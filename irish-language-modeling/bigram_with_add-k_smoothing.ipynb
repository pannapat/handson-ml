{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_pair_dict = {\n",
    "    \"a|á\": { \"keywords\": [\"a\",\"á\"], \"probability\": 0 },\n",
    "    \"ais|áis\": { \"keywords\": [\"ais\",\"áis\"], \"probability\": 0 },\n",
    "    \"aisti|aistí\": { \"keywords\": [\"aisti\",\"aistí\"], \"probability\": 0 },\n",
    "    \"ait|áit\": { \"keywords\": [\"ait\",\"áit\"], \"probability\": 0 },\n",
    "    \"ar|ár\": { \"keywords\": [\"ar\",\"ár\"], \"probability\": 0 },\n",
    "    \"arsa|ársa\": { \"keywords\": [\"arsa\",\"ársa\"], \"probability\": 0 },\n",
    "    \"ban|bán\": { \"keywords\": [\"ban\",\"bán\"], \"probability\": 0 },\n",
    "    \"cead|céad\": { \"keywords\": [\"cead\",\"céad\"], \"probability\": 0 },\n",
    "    \"chas|chás\": { \"keywords\": [\"chas\",\"chás\"], \"probability\": 0 },\n",
    "    \"chuig|chúig\": { \"keywords\": [\"chuig\",\"chúig\"], \"probability\": 0 },\n",
    "    \"dar|dár\": { \"keywords\": [\"dar\",\"dár\"], \"probability\": 0 },\n",
    "    \"do|dó\": { \"keywords\": [\"do\",\"dó\"], \"probability\": 0 },\n",
    "    \"gaire|gáire\": { \"keywords\": [\"gaire\",\"gáire\"], \"probability\": 0 },\n",
    "    \"i|í\": { \"keywords\": [\"i\",\"í\"], \"probability\": 0 },\n",
    "    \"inar|inár\": { \"keywords\": [\"inar\",\"inár\"], \"probability\": 0 },\n",
    "    \"leacht|léacht\": { \"keywords\": [\"leacht\",\"léacht\"], \"probability\": 0 },\n",
    "    \"leas|léas\": { \"keywords\": [\"leas\",\"léas\"], \"probability\": 0 },\n",
    "    \"mo|mó\": { \"keywords\": [\"mo\",\"mó\"], \"probability\": 0 },\n",
    "    \"na|ná\": { \"keywords\": [\"na\",\"ná\"], \"probability\": 0 },\n",
    "    \"os|ós\": { \"keywords\": [\"os\",\"ós\"], \"probability\": 0 },\n",
    "    \"re|ré\": { \"keywords\": [\"re\",\"ré\"], \"probability\": 0 },\n",
    "    \"scor|scór\": { \"keywords\": [\"scor\",\"scór\"], \"probability\": 0 },\n",
    "    \"te|té\": { \"keywords\": [\"te\",\"té\"], \"probability\": 0 },\n",
    "    \"teann|téann\": { \"keywords\": [\"teann\",\"téann\"], \"probability\": 0 },\n",
    "    \"thoir|thóir\": { \"keywords\": [\"thoir\",\"thóir\"], \"probability\": 0 },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    original_text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(filename, content):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(str(content))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text, is_test=False):\n",
    "    # remove punctuations !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    punctuation_list = [\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\"–\",\"€\",\"•\",\"«\",\"»\",\"’\",\"“\",\"”\",\"£\"]\n",
    "    if(is_test):\n",
    "        punctuation_list.remove('{')\n",
    "        punctuation_list.remove('}')\n",
    "        punctuation_list.remove('|')\n",
    "    for punctuation in punctuation_list:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "\n",
    "#     remove numbers\n",
    "    RE_NUMBERS = re.compile('[0-9]+')\n",
    "    text = RE_NUMBERS.sub(r'', text)\n",
    "\n",
    "    # remove emojis\n",
    "    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    text = RE_EMOJI.sub(r'', text) # ⛈ corcra❄ gorm❄\n",
    "\n",
    "    # substitute multiple spaces with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    # trim leading and trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # normalize text to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unigram(text):\n",
    "    count_dict = {}\n",
    "    unigram_words = text.split()\n",
    "\n",
    "    for word in unigram_words:\n",
    "        if word in count_dict:\n",
    "            count_dict[word] += 1\n",
    "        else:\n",
    "            count_dict[word] = 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bigram(text):\n",
    "    count_dict = {}\n",
    "    sentences = text.split('\\n')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        # trim leading and trailing spaces\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        bigram_words = sentence.split()\n",
    "\n",
    "        for i in range(len(bigram_words)):\n",
    "\n",
    "            if i == 0:\n",
    "                # a word with nothing preceding\n",
    "                preceding_word = \"^\";\n",
    "            else:\n",
    "                 # normal pairs of words   \n",
    "                preceding_word = bigram_words[i-1];\n",
    "\n",
    "            bigram = preceding_word + \" \" + bigram_words[i]\n",
    "\n",
    "            if bigram in count_dict:\n",
    "                count_dict[bigram] += 1\n",
    "            else:\n",
    "                count_dict[bigram] = 1\n",
    "\n",
    "        # count when the word is the last word of the sentence\n",
    "        bigram = bigram_words[-1] + \" $\"\n",
    "        if bigram in count_dict:\n",
    "            count_dict[bigram] += 1\n",
    "        else:\n",
    "            count_dict[bigram] = 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_unigram():\n",
    "    test_text = readfile('test.txt')\n",
    "\n",
    "    test_sentences = test_text.split(\"\\n\");\n",
    "    test_word_choices = []\n",
    "    answer_list = [\"Id,Expected\"]\n",
    "    running_number = 1\n",
    "    for sentence in test_sentences:\n",
    "        start_index = sentence.find(\"{\")\n",
    "        end_index = sentence.find(\"}\")\n",
    "\n",
    "        word_choice = sentence[start_index+1:end_index]\n",
    "        if(word_choice):\n",
    "            prob = keyword_pair_dict[word_choice][\"probability\"]\n",
    "            answer_list.append(\"{},{}\".format(running_number, prob))\n",
    "        running_number += 1\n",
    "    answer = \"\\n\".join(answer_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = generate_submission_unigram()\n",
    "# writefile('submission7.csv', submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_prob(sentence):\n",
    "    \n",
    "    start_index = sentence.find(\"{\")\n",
    "    end_index = sentence.find(\"}\")\n",
    "    \n",
    "    word_choice = sentence[(start_index+1):end_index] # \"thoir|thóir\"\n",
    "\n",
    "    if word_choice:\n",
    "        [word_choice_1, word_choice_2] = word_choice.split('|'); # word_choice_1 = \"thoir\" and word_choice_2 = \"thóir\"\n",
    "\n",
    "        words = sentence.split();\n",
    "        index = words.index(\"{\" + word_choice + \"}\")\n",
    "        if index == 0:\n",
    "            prev_word = \"^\"\n",
    "            next_word = words[1]\n",
    "\n",
    "        elif index == len(words)-1:\n",
    "            prev_word = words[index - 1]\n",
    "            next_word = \"$\"\n",
    "\n",
    "        else:\n",
    "            prev_word = words[index - 1]\n",
    "            next_word = words[index + 1]\n",
    "\n",
    "        # E.g. Tá Dora agus Bróigín ar {thoir|thóir} réalt-ainmhithe in éineacht le Pegaso.\n",
    "        # p1 = P(thoir|ar) * P(réaltainmhithe|thoir) \n",
    "        # c1 = count(\"ar thoir\") * counbt(\"thoir réaltainmhithe\")\n",
    "\n",
    "        # p2 = P(thòir|ar) * P(réaltainmhithe|thòir)\n",
    "        # c2 = count(\"ar thòir\") * count(\"thòir réaltainmhithe\")\n",
    "        # P(thoir) = p1/(p1+p2)\n",
    "        # P(thoir) = c1/(c1+c2)\n",
    "\n",
    "        word_1_bigram_1 = prev_word + \" \" + word_choice_1 # \"ar thoir\"\n",
    "        word_1_bigram_2 = word_choice_1 + \" \" + next_word # \"thoir réaltainmhithe\"\n",
    "\n",
    "        word_2_bigram_1 = prev_word + \" \" + word_choice_2 # \"ar thòir\"\n",
    "        word_2_bigram_2 = word_choice_2 + \" \" + next_word # \"thòir réaltainmhithe\"\n",
    "\n",
    "        count_word_1_bigram_1 = bigram_count_dict[word_1_bigram_1] if word_1_bigram_1 in bigram_count_dict else 0\n",
    "        count_word_1_bigram_2 = bigram_count_dict[word_1_bigram_2] if word_1_bigram_2 in bigram_count_dict else 0\n",
    "\n",
    "        count_word_2_bigram_1 = bigram_count_dict[word_2_bigram_1] if word_2_bigram_1 in bigram_count_dict else 0\n",
    "        count_word_2_bigram_2 = bigram_count_dict[word_2_bigram_2] if word_2_bigram_2 in bigram_count_dict else 0\n",
    "        \n",
    "        count_prev_word = unigram_count_dict[prev_word] if prev_word in unigram_count_dict else 0\n",
    "        count_next_word = unigram_count_dict[next_word] if next_word in unigram_count_dict else 0\n",
    "        count_keyword_1 = unigram_count_dict[word_choice_1] if word_choice_1 in unigram_count_dict else 0\n",
    "        count_keyword_2 = unigram_count_dict[word_choice_2] if word_choice_2 in unigram_count_dict else 0\n",
    "        \n",
    "        p_word_1_bigram_1 = (count_word_1_bigram_1 + K) / (count_prev_word + (K*V)) # \"ar thoir\"\n",
    "        p_word_1_bigram_2 = (count_word_1_bigram_2 + K) / (count_keyword_1 + (K*V)) # \"thoir réaltainmhithe\"\n",
    "        \n",
    "        p_word_2_bigram_1 = (count_word_2_bigram_1 + K) / (count_prev_word + (K*V)) # \"ar thòir\"\n",
    "        p_word_2_bigram_2 = (count_word_2_bigram_2 + K) / (count_keyword_2 + (K*V)) # \"thòir réaltainmhithe\"\n",
    "        \n",
    "        p1 = (p_word_1_bigram_1 * p_word_1_bigram_2)\n",
    "        p2 = (p_word_2_bigram_1 * p_word_2_bigram_2)\n",
    "        \n",
    "        prob_word_choice_1 = p1 / (p1 + p2)\n",
    "        \n",
    "    return prob_word_choice_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_bigram():\n",
    "    test_text = readfile('test.txt')\n",
    "    test_text = preprocess_data(test_text, True)\n",
    "\n",
    "    test_sentences = test_text.split(\"\\n\")\n",
    "    answer_list = [\"Id,Expected\"]\n",
    "    running_number = 1\n",
    "    for test_sentence in test_sentences:\n",
    "        if test_sentence:\n",
    "            prob = calculate_bigram_prob(test_sentence)\n",
    "\n",
    "            answer_list.append(\"{},{:.20f}\".format(running_number, prob))\n",
    "            running_number += 1\n",
    "    answer = \"\\n\".join(answer_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = readfile('train.txt')\n",
    "\n",
    "# text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "text = preprocess_data(text)\n",
    "\n",
    "# writefile(\"cleaned_train.txt\", text)\n",
    "unigram_count_dict = count_unigram(text)\n",
    "bigram_count_dict = count_bigram(text)\n",
    "\n",
    "K = 0.5\n",
    "N = len(text.split())\n",
    "V = len(unigram_count_dict)\n",
    "\n",
    "writefile('submission_bigram_add_0.5_smoothing_18.csv', generate_submission_bigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
