{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    original_text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(filename, content):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(str(content))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    # remove punctuations !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    punctuation_list = [\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\"–\",\"€\",\"•\",\"«\",\"»\",\"’\",\"“\",\"”\",\"£\"]\n",
    "    for punctuation in punctuation_list:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "\n",
    "    # remove emojis\n",
    "    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    text = RE_EMOJI.sub(r'', text)\n",
    "\n",
    "    # substitute multiple spaces with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    # normalize text to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = readfile('train.txt')\n",
    "\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "text = preprocess_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict = {}\n",
    "words = text.split()\n",
    "\n",
    "num_all_words = len(words)\n",
    "\n",
    "for word in words:\n",
    "    if word in word_count_dict:\n",
    "        word_count_dict[word] += 1\n",
    "    else:\n",
    "        word_count_dict[word] = 1\n",
    "        \n",
    "        \n",
    "#  P(thoir) = C(thoir) / [C(thoir) + C(thòir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5086159985488845\n"
     ]
    }
   ],
   "source": [
    "print(word_count_dict[\"thóir\"] / (word_count_dict[\"thóir\"] + word_count_dict[\"thoir\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_pair_dict = {\n",
    "    \"a|á\": { \"keywords\": [\"a\",\"á\"], \"probability\": 0 },\n",
    "    \"ais|áis\": { \"keywords\": [\"ais\",\"áis\"], \"probability\": 0 },\n",
    "    \"aisti|aistí\": { \"keywords\": [\"aisti\",\"aistí\"], \"probability\": 0 },\n",
    "    \"ait|áit\": { \"keywords\": [\"ait\",\"áit\"], \"probability\": 0 },\n",
    "    \"ar|ár\": { \"keywords\": [\"ar\",\"ár\"], \"probability\": 0 },\n",
    "    \"arsa|ársa\": { \"keywords\": [\"arsa\",\"ársa\"], \"probability\": 0 },\n",
    "    \"ban|bán\": { \"keywords\": [\"ban\",\"bán\"], \"probability\": 0 },\n",
    "    \"cead|céad\": { \"keywords\": [\"cead\",\"céad\"], \"probability\": 0 },\n",
    "    \"chas|chás\": { \"keywords\": [\"chas\",\"chás\"], \"probability\": 0 },\n",
    "    \"chuig|chúig\": { \"keywords\": [\"chuig\",\"chúig\"], \"probability\": 0 },\n",
    "    \"dar|dár\": { \"keywords\": [\"dar\",\"dár\"], \"probability\": 0 },\n",
    "    \"do|dó\": { \"keywords\": [\"do\",\"dó\"], \"probability\": 0 },\n",
    "    \"gaire|gáire\": { \"keywords\": [\"gaire\",\"gáire\"], \"probability\": 0 },\n",
    "    \"i|í\": { \"keywords\": [\"i\",\"í\"], \"probability\": 0 },\n",
    "    \"inar|inár\": { \"keywords\": [\"inar\",\"inár\"], \"probability\": 0 },\n",
    "    \"leacht|léacht\": { \"keywords\": [\"leacht\",\"léacht\"], \"probability\": 0 },\n",
    "    \"leas|léas\": { \"keywords\": [\"leas\",\"léas\"], \"probability\": 0 },\n",
    "    \"mo|mó\": { \"keywords\": [\"mo\",\"mó\"], \"probability\": 0 },\n",
    "    \"na|ná\": { \"keywords\": [\"na\",\"ná\"], \"probability\": 0 },\n",
    "    \"os|ós\": { \"keywords\": [\"os\",\"ós\"], \"probability\": 0 },\n",
    "    \"re|ré\": { \"keywords\": [\"re\",\"ré\"], \"probability\": 0 },\n",
    "    \"scor|scór\": { \"keywords\": [\"scor\",\"scór\"], \"probability\": 0 },\n",
    "    \"te|té\": { \"keywords\": [\"te\",\"té\"], \"probability\": 0 },\n",
    "    \"teann|téann\": { \"keywords\": [\"teann\",\"téann\"], \"probability\": 0 },\n",
    "    \"thoir|thóir\": { \"keywords\": [\"thoir\",\"thóir\"], \"probability\": 0 },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_1 = keyword_pair_map[0][0];\n",
    "# word_2 = keyword_pair_map[0][1];\n",
    "# prob_word_1 = word_count_dict[word_1]\n",
    "# prob_word_2 = word_count_dict[word_2]\n",
    "\n",
    "# normalized_prob = prob_word_1 / (prob_word_1 + prob_word_2)\n",
    "# print(normalized_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keyword_pair_dict:\n",
    "    word_1 = keyword_pair_dict[key][\"keywords\"][0]\n",
    "    word_2 = keyword_pair_dict[key][\"keywords\"][1]\n",
    "    prob_word_1 = word_count_dict[word_1]\n",
    "    prob_word_2 = word_count_dict[word_2]\n",
    "    \n",
    "    normalized_prob_word_1 = prob_word_1 / (prob_word_1 + prob_word_2)\n",
    "    \n",
    "    keyword_pair_dict[key][\"probability\"] = normalized_prob_word_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission():\n",
    "    test_text = readfile('test.txt')\n",
    "\n",
    "    test_sentences = test_text.split(\"\\n\");\n",
    "    test_word_choices = []\n",
    "    answer_list = [\"Id,Expected\"]\n",
    "    running_number = 1\n",
    "    for sentence in test_sentences:\n",
    "        start_index = sentence.find(\"{\")\n",
    "        end_index = sentence.find(\"}\")\n",
    "\n",
    "        word_choice = sentence[start_index+1:end_index]\n",
    "        if(word_choice):\n",
    "            prob = keyword_pair_dict[word_choice][\"probability\"]\n",
    "            answer_list.append(\"{},{}\".format(running_number, prob))\n",
    "        running_number += 1\n",
    "    answer = \"\\n\".join(answer_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = generate_submission()\n",
    "writefile('submission7.csv', submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
