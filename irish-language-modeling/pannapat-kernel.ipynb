{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_pair_map = {\n",
    "    0: [\"a\",\"á\"],\n",
    "    1: [\"ais\",\"áis\"],\n",
    "    2: [\"aisti\",\"aistí\"],\n",
    "    3: [\"ait\",\"áit\"],\n",
    "    4: [\"ar\",\"ár\"],\n",
    "    5: [\"arsa\",\"ársa\"],\n",
    "    6: [\"ban\",\"bán\"],\n",
    "    7: [\"cead\",\"céad\"],\n",
    "    8: [\"chas\",\"chás\"],\n",
    "    9: [\"chuig\",\"chúig\"],\n",
    "    10: [\"dar\",\"dár\"],\n",
    "    11: [\"do\",\"dó\"],\n",
    "    12: [\"gaire\",\"gáire\"],\n",
    "    13: [\"i\",\"í\"],\n",
    "    14: [\"inar\",\"inár\"],\n",
    "    15: [\"leacht\",\"léacht\"],\n",
    "    16: [\"leas\",\"léas\"],\n",
    "    17: [\"mo\",\"mó\"],\n",
    "    18: [\"na\",\"ná\"],\n",
    "    19: [\"os\",\"ós\"],\n",
    "    20: [\"re\",\"ré\"],\n",
    "    21: [\"scor\",\"scór\"],\n",
    "    22: [\"te\",\"té\"],\n",
    "    23: [\"teann\",\"téann\"],\n",
    "    24: [\"thoir\",\"thóir\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text\n",
    "def readfile(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    original_text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(filename, content):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(str(content))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text):\n",
    "    # remove punctuations !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    punctuation_list = [\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\"–\",\"€\",\"•\",\"«\",\"»\",\"’\",\"“\",\"”\",\"£\"]\n",
    "    for punctuation in punctuation_list:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "\n",
    "    # remove emojis\n",
    "    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    text = RE_EMOJI.sub(r'', text)\n",
    "\n",
    "    # substitute multiple spaces with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    # normalize text to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = readfile('train.txt')\n",
    "text = preprocess_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize text to a list of sentences\n",
    "sentences = text.split(\"\\n\")\n",
    "\n",
    "sentence_map = {k: [] for k in keyword_pair_map}\n",
    "for sentence in sentences:\n",
    "    for i, (key, keyword_pair) in enumerate(keyword_pair_map.items()):\n",
    "        if(keyword_pair[0] in sentence or keyword_pair[1] in sentence):\n",
    "            sentence_map[key].append(sentence);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_map = {}\n",
    "for key in sentence_map:\n",
    "    sentence_list = sentence_map[key]\n",
    "    keyword_pair = keyword_pair_map[key]\n",
    "    count_1 = 0\n",
    "    count_2 = 0\n",
    "    prob_1 = 0;\n",
    "    prob_2 = 0\n",
    "    \n",
    "    for sentence in sentence_list:\n",
    "        if keyword_pair[0] in sentence:\n",
    "            count_1 += 1;\n",
    "        if keyword_pair[1] in sentence:\n",
    "            count_2 += 1\n",
    "\n",
    "    num_sentences = len(sentence_list)\n",
    "    prob_1 = count_1 / num_sentences\n",
    "    prob_2 = count_2 / num_sentences\n",
    "    prob_map[keyword_pair[0]] = prob_1\n",
    "    prob_map[keyword_pair[1]] = prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_choice():\n",
    "    test_text = readfile('test.txt')\n",
    "\n",
    "    test_sentences = test_text.split(\"\\n\");\n",
    "    test_word_choices = []\n",
    "    answer_list = [\"Id,Expected\"]\n",
    "    running_number = 1\n",
    "    for sentence in test_sentences:\n",
    "        start_index = sentence.find(\"{\")\n",
    "        end_index = sentence.find(\"}\")\n",
    "\n",
    "        word_choice = sentence[start_index+1:end_index]\n",
    "        if(word_choice):\n",
    "            word_choice_pair = word_choice.split(\"|\")\n",
    "            answer_list.append(\"{},{}\".format(running_number, (1- (prob_map[word_choice_pair[1]]))))\n",
    "        running_number += 1\n",
    "    answer = \"\\n\".join(answer_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = generate_submission_choice()\n",
    "writefile('submission7.csv', submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
