{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "  \"a\",\"á\",\"ais\",\"áis\",\"aisti\",\"aistí\",\"ait\",\"áit\",\"ar\",\"ár\",\"arsa\",\"ársa\",\"ban\",\"bán\",\"cead\",\"céad\",\"chas\",\"chás\",\"chuig\",\"chúig\",\"dar\",\"dár\",\"do\",\"dó\",\"gaire\",\"gáire\",\"i\",\"í\",\"inar\",\"inár\",\"leacht\",\"léacht\",\"leas\",\"léas\",\"mo\",\"mó\",\"na\",\"ná\",\"os\",\"ós\",\"re\",\"ré\",\"scor\",\"scór\",\"te\",\"té\",\"teann\",\"téann\",\"thoir\",\"thóir\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    original_text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(filename, content):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(str(content))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits\n",
    "\n",
    "def preprocess_data(text):\n",
    "    # remove punctuations !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    punctuation_list = [\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\"–\",\"€\",\"•\",\"«\",\"»\",\"’\",\"“\",\"”\",\"£\"]\n",
    "    for punctuation in punctuation_list:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "\n",
    "#     remove numbers\n",
    "#     RE_NUMBERS = re.compile('[0-9]+')\n",
    "#     text = RE_NUMBERS.sub(r'', text)\n",
    "    \n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)\n",
    "\n",
    "    # remove emojis\n",
    "    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    text = RE_EMOJI.sub(r'', text) # ⛈ corcra❄ gorm❄\n",
    "\n",
    "    # substitute multiple spaces with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    # trim leading and trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # normalize text to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# K = 0.5\n",
    "# N = len(tokens)\n",
    "# V = len(unigram_count_dict)\n",
    "\n",
    "mini_train_text = readfile('mini_train.txt')\n",
    "train_text = readfile('mini_train.txt')\n",
    "\n",
    "# test_set = readfile('test.txt')\n",
    "\n",
    "# text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "train_text = preprocess_data(train_text)\n",
    "mini_train_text = preprocess_data(mini_train_text)\n",
    "\n",
    "train_text = train_text.splitlines()\n",
    "mini_train_text = mini_train_text.splitlines()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# vectorizer = CountVectorizer(analyzer='word',ngram_range=(1, 2), vocabulary=vocab)\n",
    "\n",
    "# vector = vectorizer.fit_transform([\"Nuair atá cúiseanna á gcur ar an taifead poiblí, nó le linn ráiteas poiblí a dhéanamh, ní mór don ionchúisitheoir cúram a ghlacadh gan náire a chur ar an gcúisí ná ar fhinnéithe trí eolas a nochtadh nach gcuirfear ar fáil go poiblí murach sin.\"]).toarray()\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "analyzer = bigram_vectorizer.build_analyzer()\n",
    "analyzer(train_text[0])\n",
    "\n",
    "X_2 = bigram_vectorizer.fit_transform(train_text).toarray()\n",
    "\n",
    "# writefile('submission_bigram_add_1_smoothing_16.csv', generate_submission_bigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "# analyze(train_text[0])\n",
    "\n",
    "X_2 = bigram_vectorizer.fit_transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-0fca04c6607a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame[X_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1940 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 72 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "corpus = train_text\n",
    "vectorizer = HashingVectorizer(n_features=2**5,ngram_range=(1,2),norm='l1',alternate_sign=False)\n",
    "X = vectorizer.fit_transform(train_text)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01265823, 0.01265823, 0.02531646, 0.05063291, 0.05063291,\n",
       "       0.01265823, 0.01265823, 0.02531646, 0.02531646, 0.05063291,\n",
       "       0.02531646, 0.01265823, 0.05063291, 0.02531646, 0.03797468,\n",
       "       0.02531646, 0.01265823, 0.02531646, 0.        , 0.        ,\n",
       "       0.03797468, 0.03797468, 0.02531646, 0.05063291, 0.05063291,\n",
       "       0.06329114, 0.01265823, 0.02531646, 0.05063291, 0.08860759,\n",
       "       0.03797468, 0.02531646])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
