{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_pair_dict = {\n",
    "    \"a|á\": { \"keywords\": [\"a\",\"á\"], \"probability\": 0 },\n",
    "    \"ais|áis\": { \"keywords\": [\"ais\",\"áis\"], \"probability\": 0 },\n",
    "    \"aisti|aistí\": { \"keywords\": [\"aisti\",\"aistí\"], \"probability\": 0 },\n",
    "    \"ait|áit\": { \"keywords\": [\"ait\",\"áit\"], \"probability\": 0 },\n",
    "    \"ar|ár\": { \"keywords\": [\"ar\",\"ár\"], \"probability\": 0 },\n",
    "    \"arsa|ársa\": { \"keywords\": [\"arsa\",\"ársa\"], \"probability\": 0 },\n",
    "    \"ban|bán\": { \"keywords\": [\"ban\",\"bán\"], \"probability\": 0 },\n",
    "    \"cead|céad\": { \"keywords\": [\"cead\",\"céad\"], \"probability\": 0 },\n",
    "    \"chas|chás\": { \"keywords\": [\"chas\",\"chás\"], \"probability\": 0 },\n",
    "    \"chuig|chúig\": { \"keywords\": [\"chuig\",\"chúig\"], \"probability\": 0 },\n",
    "    \"dar|dár\": { \"keywords\": [\"dar\",\"dár\"], \"probability\": 0 },\n",
    "    \"do|dó\": { \"keywords\": [\"do\",\"dó\"], \"probability\": 0 },\n",
    "    \"gaire|gáire\": { \"keywords\": [\"gaire\",\"gáire\"], \"probability\": 0 },\n",
    "    \"i|í\": { \"keywords\": [\"i\",\"í\"], \"probability\": 0 },\n",
    "    \"inar|inár\": { \"keywords\": [\"inar\",\"inár\"], \"probability\": 0 },\n",
    "    \"leacht|léacht\": { \"keywords\": [\"leacht\",\"léacht\"], \"probability\": 0 },\n",
    "    \"leas|léas\": { \"keywords\": [\"leas\",\"léas\"], \"probability\": 0 },\n",
    "    \"mo|mó\": { \"keywords\": [\"mo\",\"mó\"], \"probability\": 0 },\n",
    "    \"na|ná\": { \"keywords\": [\"na\",\"ná\"], \"probability\": 0 },\n",
    "    \"os|ós\": { \"keywords\": [\"os\",\"ós\"], \"probability\": 0 },\n",
    "    \"re|ré\": { \"keywords\": [\"re\",\"ré\"], \"probability\": 0 },\n",
    "    \"scor|scór\": { \"keywords\": [\"scor\",\"scór\"], \"probability\": 0 },\n",
    "    \"te|té\": { \"keywords\": [\"te\",\"té\"], \"probability\": 0 },\n",
    "    \"teann|téann\": { \"keywords\": [\"teann\",\"téann\"], \"probability\": 0 },\n",
    "    \"thoir|thóir\": { \"keywords\": [\"thoir\",\"thóir\"], \"probability\": 0 },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    file = open(filename, 'rt')\n",
    "    original_text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(filename, content):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(str(content))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text, is_test=False):\n",
    "    # remove punctuations !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "    punctuation_list = [\"!\",\"\\\"\",\"#\",\"$\",\"%\",\"&\",\"'\",\"(\",\")\",\"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\"–\",\"€\",\"•\",\"«\",\"»\",\"’\",\"“\",\"”\",\"£\"]\n",
    "    if(is_test):\n",
    "        punctuation_list.remove('{')\n",
    "        punctuation_list.remove('}')\n",
    "        punctuation_list.remove('|')\n",
    "    for punctuation in punctuation_list:\n",
    "        text = text.replace(punctuation, \"\")\n",
    "\n",
    "    # remove numbers\n",
    "    RE_NUMBERS = re.compile('[0-9]+')\n",
    "    text = RE_NUMBERS.sub(r'', text)\n",
    "\n",
    "    # remove emojis\n",
    "    RE_EMOJI = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "    text = RE_EMOJI.sub(r'', text) # still have ⛈ corcra❄ gorm❄\n",
    "\n",
    "    # substitute multiple spaces with a single space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    # trim leading and trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # normalize text to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unigram(text):\n",
    "    count_dict = {}\n",
    "    unigram_words = text.split()\n",
    "\n",
    "    for word in unigram_words:\n",
    "        if word in count_dict:\n",
    "            count_dict[word] += 1\n",
    "        else:\n",
    "            count_dict[word] = 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bigram(text):\n",
    "    count_dict = {}\n",
    "    sentences = text.split(\"\\n\")\n",
    "\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        # trim leading and trailing spaces\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        bigram_words = sentence.split()\n",
    "\n",
    "        for i in range(len(bigram_words)):\n",
    "\n",
    "            if i == 0:\n",
    "                # a word with nothing preceding\n",
    "                preceding_word = \"^\";\n",
    "            else:\n",
    "                 # normal pairs of words   \n",
    "                preceding_word = bigram_words[i-1];\n",
    "\n",
    "            bigram = preceding_word + \" \" + bigram_words[i]\n",
    "\n",
    "            if bigram in count_dict:\n",
    "                count_dict[bigram] += 1\n",
    "            else:\n",
    "                count_dict[bigram] = 1\n",
    "\n",
    "        # count when the word is the last word of the sentence\n",
    "        bigram = bigram_words[-1] + \" $\"\n",
    "        if bigram in count_dict:\n",
    "            count_dict[bigram] += 1\n",
    "        else:\n",
    "            count_dict[bigram] = 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trigram(text):\n",
    "    count_dict = {}\n",
    "    sentences = text.split(\"\\n\")\n",
    "\n",
    "    for sentence in sentences:\n",
    "        \n",
    "        # trim leading and trailing spaces\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        sentence = \"^ \" + sentence + \" $\"\n",
    "        words = sentence.split()\n",
    "\n",
    "        for i in range(len(words)-2):\n",
    "            word_k_2 = words[i];\n",
    "            word_k_1 = words[i+1]\n",
    "            word_k = words[i+2]\n",
    "            \n",
    "            trigram = word_k_2 + \" \" + word_k_1 + \" \" + word_k\n",
    "\n",
    "            if trigram in count_dict:\n",
    "                count_dict[trigram] += 1\n",
    "            else:\n",
    "                count_dict[trigram] = 1\n",
    "\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_trigram_prob(sentence):\n",
    "    sentence = \"^ \" + sentence + \" $\" # this guarantee that index of {w|w'} won't be 0 or length - 1\n",
    "    start_index = sentence.find(\"{\")\n",
    "    end_index = sentence.find(\"}\")\n",
    "    \n",
    "    word_choice = sentence[(start_index+1):end_index] # \"thoir|thóir\"\n",
    "\n",
    "    if word_choice:\n",
    "        [word_choice_1, word_choice_2] = word_choice.split('|'); # word_choice_1 = \"thoir\" and word_choice_2 = \"thóir\"\n",
    "\n",
    "        words = sentence.split();\n",
    "        index = words.index(\"{\" + word_choice + \"}\")\n",
    "        \n",
    "        w_k_minus_2 = words[index-2] if index >= 2 else \"\"\n",
    "        w_k_minus_1 = words[index-1] if index >= 1 else \"\"\n",
    "        w_k = word_choice_1\n",
    "        w_k_prime = word_choice_2\n",
    "        w_k_plus_1 = words[index+1] if index+1 < len(words) else \"\"\n",
    "        w_k_plus_2 = words[index+2] if index+2 < len(words) else \"\"\n",
    "        \n",
    "        word_1_bigram_1 = (w_k_minus_2 + \" \" + w_k_minus_1).replace('  ',' ')\n",
    "        word_1_bigram_2 = (w_k_minus_1 + \" \" + word_choice_1).replace('  ',' ')\n",
    "        word_1_bigram_3 = (word_choice_1 + \" \" + w_k_plus_1).replace('  ',' ')\n",
    "        \n",
    "        word_2_bigram_1 = (w_k_minus_2 + \" \" + w_k_minus_1).replace('  ',' ')\n",
    "        word_2_bigram_2 = (w_k_minus_1 + \" \" + word_choice_2).replace('  ',' ')\n",
    "        word_2_bigram_3 = (word_choice_2 + \" \" + w_k_plus_1).replace('  ',' ')\n",
    "\n",
    "        count_word_1_bigram_1 = bigram_count_dict[word_1_bigram_1] if word_1_bigram_1 in bigram_count_dict else 0\n",
    "        count_word_1_bigram_2 = bigram_count_dict[word_1_bigram_2] if word_1_bigram_2 in bigram_count_dict else 0\n",
    "        count_word_1_bigram_3 = bigram_count_dict[word_1_bigram_3] if word_1_bigram_3 in bigram_count_dict else 0\n",
    "        \n",
    "        count_word_2_bigram_1 = bigram_count_dict[word_2_bigram_1] if word_2_bigram_1 in bigram_count_dict else 0\n",
    "        count_word_2_bigram_2 = bigram_count_dict[word_2_bigram_2] if word_2_bigram_2 in bigram_count_dict else 0\n",
    "        count_word_2_bigram_3 = bigram_count_dict[word_2_bigram_3] if word_2_bigram_3 in bigram_count_dict else 0\n",
    "        \n",
    "        \n",
    "        word_1_trigram_1 = (w_k_minus_2 + \" \" + w_k_minus_1 + \" \" + w_k).replace('  ',' ')\n",
    "        word_1_trigram_2 = (w_k_minus_1 + \" \" + w_k + \" \" + w_k_plus_1).replace('  ',' ')\n",
    "        word_1_trigram_3 = (w_k + \" \" + w_k_plus_1 + \" \" + w_k_plus_2).replace('  ',' ')\n",
    "        \n",
    "        word_2_trigram_1 = (w_k_minus_2 + \" \" + w_k_minus_1 + \" \" + w_k_prime).replace('  ',' ')\n",
    "        word_2_trigram_2 = (w_k_minus_1 + \" \" + w_k_prime + \" \" + w_k_plus_1).replace('  ',' ')\n",
    "        word_2_trigram_3 = (w_k_prime + \" \" + w_k_plus_1 + \" \" + w_k_plus_2).replace('  ',' ')\n",
    "       \n",
    "        \n",
    "    \n",
    "        # E.g. Tá Dora agus Bróigín ar {thoir|thóir} réalt-ainmhithe in éineacht le Pegaso.\n",
    "        # p1 = P(thoir|Bróigín ar) * P(réaltainmhithr|ar thoir) * P(in|thoir réaltainmhithr)\n",
    "        # c1 = count(\"Bróigín ar thoir\") * count(\"ar thoir réaltainmhithe\") * count(thoir réaltainmhithr in)\n",
    "\n",
    "        # p2 = P(thòir|Bróigín ar) * P(réaltainmhithr|ar thòir) * P(in|thòir réaltainmhithr)\n",
    "        # c2 = count(\"Bróigín ar thòir\") * count(\"ar thòir réaltainmhithe\") * count(thòir réaltainmhithr in)\n",
    "        \n",
    "        # P(thoir) = p1/(p1+p2)\n",
    "        # P(thoir) = c1/(c1+c2)\n",
    "\n",
    "        count_word_1_trigram_1 = trigram_count_dict[word_1_trigram_1] if word_1_trigram_1 in trigram_count_dict else 0\n",
    "        count_word_1_trigram_2 = trigram_count_dict[word_1_trigram_2] if word_1_trigram_2 in trigram_count_dict else 0\n",
    "        count_word_1_trigram_3 = trigram_count_dict[word_1_trigram_3] if word_1_trigram_3 in trigram_count_dict else 0\n",
    "\n",
    "        count_word_2_trigram_1 = trigram_count_dict[word_2_trigram_1] if word_2_trigram_1 in trigram_count_dict else 0\n",
    "        count_word_2_trigram_2 = trigram_count_dict[word_2_trigram_2] if word_2_trigram_2 in trigram_count_dict else 0\n",
    "        count_word_2_trigram_3 = trigram_count_dict[word_2_trigram_3] if word_2_trigram_3 in trigram_count_dict else 0\n",
    "\n",
    "        # calculate using conditional probabilities + add-k smoothing\n",
    "        p_word_1_trigram_1 = (count_word_1_trigram_1 + K) / (count_word_1_bigram_1 + (K*V))\n",
    "        p_word_1_trigram_2 = (count_word_1_trigram_2 + K) / (count_word_1_bigram_2 + (K*V))\n",
    "        p_word_1_trigram_3 = (count_word_1_trigram_3 + K) / (count_word_1_bigram_3 + (K*V))\n",
    "\n",
    "        p_word_2_trigram_1 = (count_word_2_trigram_1 + K) / (count_word_2_bigram_1 + (K*V))\n",
    "        p_word_2_trigram_2 = (count_word_2_trigram_2 + K) / (count_word_2_bigram_2 + (K*V))\n",
    "        p_word_2_trigram_3 = (count_word_2_trigram_3 + K) / (count_word_2_bigram_3 + (K*V))\n",
    "\n",
    "        p1 = (p_word_1_trigram_1 * p_word_1_trigram_2) * p_word_1_trigram_3\n",
    "        p2 = (p_word_2_trigram_1 * p_word_2_trigram_2) * p_word_2_trigram_3\n",
    "\n",
    "        prob_word_choice_1 = p1 / (p1 + p2)\n",
    "        \n",
    "    return prob_word_choice_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigram_submission():\n",
    "    test_text = readfile('test.txt')\n",
    "    test_text = preprocess_data(test_text, True)\n",
    "\n",
    "    test_sentences = test_text.split(\"\\n\")\n",
    "    answer_list = [\"Id,Expected\"]\n",
    "    running_number = 1\n",
    "    for test_sentence in test_sentences:\n",
    "        if test_sentence:\n",
    "            prob = calculate_trigram_prob(test_sentence)\n",
    "\n",
    "            answer_list.append(\"{},{:.20f}\".format(running_number, prob))\n",
    "            running_number += 1\n",
    "    answer = \"\\n\".join(answer_list)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = readfile('train.txt')\n",
    "\n",
    "text = preprocess_data(text)\n",
    "\n",
    "unigram_count_dict = count_unigram(text)\n",
    "bigram_count_dict = count_bigram(text)\n",
    "trigram_count_dict = count_trigram(text)\n",
    "\n",
    "K = 0.1\n",
    "N = len(text.split())\n",
    "V = len(unigram_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writefile('submission_trigram_add_0.1_smoothing_21.csv', generate_trigram_submission())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
